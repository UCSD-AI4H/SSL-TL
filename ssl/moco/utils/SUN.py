import torch.utils.data as datafrom PIL import Imageimport osimport numpy as npclass SUNDataset(data.Dataset):    def __init__(self, root, number_per_class=225,mode = 'train',transforms=None):        self.root = root        self.number_per_class_need = number_per_class        self.images = []        self.labels = []        self.classes = list(np.loadtxt(os.path.join(self.root,'ClassName.txt'),dtype=str))        print('Number of classes {}'.format(len(self.classes)))        for i,c in enumerate(self.classes):            cls_dir = self.root+ c            num_exist = len(os.listdir(cls_dir))            number_per_class = min(self.number_per_class_need, num_exist)            print(number_per_class,c)            cls_list = [os.path.join(cls_dir, item) for item in os.listdir(cls_dir)][:number_per_class]            self.images.extend(cls_list)            self.labels.extend(number_per_class * [i])        self.transforms = transforms        # self.test_read()        print('Number of images {}'.format(len(self.images)))    def test_read(self):        for i,imgname in enumerate(self.images):            try:                img = Image.open(imgname)            except:                print("bad image {}".format(imgname))                self.images.pop(i)                self.labels.pop(i)    def __len__(self):        return len(self.labels)    def __getitem__(self, index):        """        Args:            index (int): Index        Returns:            tuple: (image, target) where target is index of the target class.        """        img = Image.open(self.images[index]).convert('RGB')        target = self.labels[index]        if self.transforms:            img = self.transforms(img)        return img, target